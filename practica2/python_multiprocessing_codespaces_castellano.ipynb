{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVl91tpNYssb"
      },
      "source": [
        "# Procesamiento paralelo en Python\n",
        "\n",
        "El número de librerías y paquetes para el procesamiento paralelo en Python es enorme. Consulta este enlace para obtener una visión general (https://wiki.python.org/moin/ParallelProcessing).\n",
        "\n",
        "En esta sesión presentamos multiprocessing, uno de los frameworks más importantes para implementar aplicaciones paralelas en Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxp63V94ypR-"
      },
      "source": [
        "# Módulo multiprocessing de Python\n",
        "\n",
        "El módulo `multiprocessing` (https://docs.python.org/3/library/multiprocessing.html) es una biblioteca potente y versátil incluida en la distribución estándar de Python, diseñada para facilitar la ejecución concurrente/paralela mediante la creación de múltiples procesos. Proporciona una interfaz de alto nivel para la creación y gestión de procesos, así como una amplia variedad de herramientas de bajo nivel para construir sistemas complejos de comunicación y sincronización entre procesos.\n",
        "\n",
        "A diferencia de los hilos, que operan dentro del mismo espacio de memoria y están sujetos al Global Interpreter Lock (GIL), `multiprocessing` crea procesos separados con espacios de memoria individuales. Esto permite un paralelismo real en procesadores multinúcleo. El caso ideal sería ejecutar un proceso por cada procesador físico; de esta forma extraeríamos el máximo potencial de paralelismo de nuestro procesador.\n",
        "\n",
        "El módulo incluye herramientas para:\n",
        "\n",
        "- Crear y gestionar procesos.\n",
        "- Compartir datos entre procesos mediante memoria compartida.\n",
        "- Establecer canales de comunicación como `Pipes` y `Queues`.\n",
        "- Sincronizar operaciones con primitivas tales como `Locks`, `Events`, `Semaphores` y `Conditions`.\n",
        "\n",
        "La biblioteca ofrece tanto primitivas de bajo nivel para usuarios avanzados como abstracciones de alto nivel para facilitar su uso. La clase `Process` es la interfaz principal de bajo nivel para la creación de procesos. Otras clases  de nivel superior, como `Pools`, permiten gestionar de forma sencilla grupos de procesos, evitando las complicaciones propias de la comunicación y sincronización de bajo nivel entre ellos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBzWDv5GtxHI"
      },
      "source": [
        "---\n",
        "Parte del código en este notebook está basado en las siguientes fuentes:\n",
        "\n",
        "- Python 201, Michael Driscoll\n",
        "- https://www.machinelearningplus.com/python/parallel-processing-python/\n",
        "- https://github.com/mmckerns/tuthpc\n",
        "- https://github.com/csc-training/hpc-python\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2bdUt3vyBuA"
      },
      "source": [
        "### Indentifica el número de núcleos en tu computadora\n",
        "\n",
        "El número de procesos debería estar relacionado con la cantidad de núcleos físicos de tu equipo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GwWxFkM6_Hs"
      },
      "outputs": [],
      "source": [
        "# comprueba el número de nucleos\n",
        "import multiprocessing as mp\n",
        "\n",
        "# multiprocessing cpu_count solo te proporciona el número de nucleos lógicos (recuerda que los procesadores pueden tener tecnologías como SMT)\n",
        "print(\"Number of logical cores: \", mp.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0h8yc6Ay3l_"
      },
      "outputs": [],
      "source": [
        "# utiliza psutil para obtener información más detallada\n",
        "import psutil\n",
        "\n",
        "# Número de nucleos lógicos\n",
        "logical_cores_psutil = psutil.cpu_count(logical=True)\n",
        "\n",
        "# Número de nucleos físicos\n",
        "physical_cores_psutil = psutil.cpu_count(logical=False)\n",
        "\n",
        "# Imprime los resultados\n",
        "print(f\"Logical Cores (psutil): {logical_cores_psutil}\")\n",
        "print(f\"Physical Cores (psutil): {physical_cores_psutil}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzfYtz2tASt0"
      },
      "source": [
        "## La clase `Process` (paralelismo de procesos a bajo nivel)\n",
        "\n",
        "La clase `Process` permite crear procesos individuales que llaman a una o varias funciones definidas por el usuario.\n",
        "\n",
        "Debes crear el proceso y llamar a su método `start()`. Luego, simplemente invoca el método `join()` para todos los procesos que has creado.\n",
        "Esto es necesario para sincronizar la ejecución de todos tus procesos, esperando a que todos terminen para continuar la ejecución de la aplicación. Si necesitas detener un proceso, puedes llamar a su método `terminate()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxfUJRkpzX4r"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Process\n",
        "import os\n",
        "\n",
        "def doubler(number):\n",
        "  \"\"\"\n",
        "  Función que duplica el valor de entrada y puede ser asignada a un proceso\n",
        "  \"\"\"\n",
        "  result = number * 2\n",
        "  proc = os.getpid()\n",
        "  print(f'{number} doubled to {result} by process id: {proc} ')\n",
        "\n",
        "numbers = [5, 10, 15, 20, 25]\n",
        "\n",
        "procs_list = []\n",
        "# cada proceso puede recibir una función a implementar distinta y/o parámetros independientes\n",
        "for index, number in enumerate(numbers):\n",
        "  p = Process(target=doubler, args=[number]) # args requiere un elemento iterable\n",
        "  procs_list.append(p)\n",
        "  p.start()\n",
        "\n",
        "# Espera a que todos los procesos terminen\n",
        "for p in procs_list:\n",
        "  p.join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1nkg_KaNkzu"
      },
      "source": [
        "Sin embargo, con este enfoque, obtener los valores de salida de cada proceso requeriría utilizar clases específicas como `multiprocessing.Queue` o `multiprocessing.Manager`. Por lo tanto, se trata de un enfoque complejo, que se utiliza principalmente para generar procesos no relacionados que trabajan de manera independiente (generalmente, no es el caso en la computación científica)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Nf6RX7dBTec"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "def tarea():\n",
        "    return 42  # Este valor no se puede recuperar directamente ya que el proceso padre y el hijo no comparten memoria\n",
        "\n",
        "p = Process(target=tarea)\n",
        "p.start()\n",
        "p.join()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrMfirV2BTed"
      },
      "source": [
        "El siguiente código muestra cómo el proceso hijo puede enviar un valor al proceso padre utilizando un objeto `Queue`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytwupkblBTed"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def tarea(q):\n",
        "    q.put(42)  # Almacete el valor en el objeto de tipo queue\n",
        "\n",
        "q = Queue()\n",
        "p = Process(target=tarea, args=(q,))\n",
        "p.start()\n",
        "p.join()\n",
        "\n",
        "resultado = q.get()\n",
        "print(f'Received value = {resultado}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K-MpvmOBTed"
      },
      "source": [
        "NOTA IMPORTANTE: Cuando creas múltiples procesos utilizando `multiprocessing.Process`, cada proceso se ejecuta de forma independiente y posee su propio espacio de memoria. Esto significa que no pueden compartir fácilmente resultados entre sí ni con el proceso principal. Se recomienda utilizar procesos para paralelizar tareas cuando son independientes y no requieren compartir información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QuE3eS4_00j"
      },
      "source": [
        "## La clase Pool\n",
        "\n",
        "**La clase `Pool` se utiliza para representar un conjunto de procesos `worker`**. Tiene métodos que te permiten delegar tareas a los procesos `worker`.\n",
        "\n",
        "**Es más fácil de trabajar con ella y de un nivel superior que la clase `Process`.**\n",
        "\n",
        "El proceso Master envía tareas a los workers, los workers ejecutan las tareas y, finalmente, el Master recupera los resultados de los workers.\n",
        "\n",
        "Los métodos más utilizados en la clase ``Pool`` Class son (aunque existen muchos más):\n",
        "\n",
        "\n",
        "1. Ejecución síncrona (bloqueante): Los procesos se completan en el mismo orden en el que fueron iniciados. Esto se logra bloqueando el programa principal hasta que los respectivos procesos hayan finalizado.\n",
        "  - ``Pool.map()`` and ``Pool.starmap()``\n",
        "  - ``Pool.apply()``\n",
        "\n",
        "\n",
        "2. Ejecución asíncrona (no bloqueante): El proceso principal no se bloquea. Como resultado, el orden de los resultados puede alterarse, pero generalmente se realiza el trabajo de forma más rápida.\n",
        "  - ``Pool.map_async()`` and ``Pool.starmap_async()``\n",
        "  - ``Pool.apply_async()``\n",
        "\n",
        "El método `map` es aplicable cuando el proceso que vamos a crear se mapea a una función que acepta un único argumento. Para funciones que necesitan múltiples argumentos, se debe utilizar el método `starmap` en su lugar. Ambas versiones reciben un iterable y lo dividen en tareas, donde cada tarea tiene la misma función objetivo (mapeada).\n",
        "\n",
        "Con respecto a `apply` y `apply_async`, ambos reciben un argumento `args` que acepta los parámetros que se le pasan a la función que se va a asignar a las tareas (la que estamos paralelizando) como argumento, a diferencia de map y de forma similar a starmap. Sin embargo en el caso de `apply` solo realiza una única llamada a la función a paralelizar. ¿Qué significa esto? Para paralelizar realmente la función tienes que iterar manualmente haciendo varias llamadas a `apply` para aprovechar el `pool` de workers. Esto tiene la ventaja de que, en cada llamada, puedes especificar no solo una nueva porción de datos sobre la que trabajará el worker, sino también una tarea completamente diferente (otra función) a ejecutar en ese worker. Es decir, puedes pasar una lista de tareas y una lista de datos con los argumentos para cada tarea.\n",
        "\n",
        "Para más info sobre apply_async ver:\n",
        "\n",
        "https://stackoverflow.com/questions/53035293/purpose-of-multiprocessing-pool-apply-and-multiprocessing-pool-apply-async\n",
        "\n",
        "https://stackoverflow.com/questions/52985131/how-to-write-a-multithreaded-function-for-processing-different-tasks-concurrentl/52992065#52992065\n",
        "\n",
        "https://docs.python.org/3.8/library/multiprocessing.html#multiprocessing.pool.Pool.apply_async\n",
        "\n",
        "En tareas intensivas en cómputo, normalmente el problema consiste en aplicar la misma función a una gran cantidad de datos; por ello, en esta práctica nos centraremos en `map` y a los métodos derivados.\n",
        "\n",
        "Otros métodos el paquete `Multiprocessing` permiten la creación de `pipes`, `queues` y otros enfoques, **pero el `pool` de workers es, con diferencia, el enfoque más típico y sencillo para paralelizar entre los núcleos de un solo ordenador.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSi-dLyq2ArP"
      },
      "outputs": [],
      "source": [
        "# Tabla resumen de los métodos de paquete Pool\n",
        "# ----------------------------------------------------------------------------------------------\n",
        "#                           |          Una única función              |  Funciones múltiples   |\n",
        "# ----------------------------------------------------------------------------------------------\n",
        "#                           |  Un Argumento    |  Varios Argumentos   |  Varios Argumentos     |\n",
        "# ----------------------------------------------------------------------------------------------\n",
        "# sync process (blocking)   | Pool.map         | Pool.starmap         |  Pool.apply            |\n",
        "#\n",
        "# async proc (non-blocking) | Pool.map_async   | Pool.starmap_async   |  Pool.apply_async      |\n",
        "# ----------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JckTK9E8XyYp"
      },
      "source": [
        "### Uso de Pool.map\n",
        "\n",
        "Todas las funciones `map` de `Multiprocessing` para un `pool` de workers se comportan de manera similar a la función `map` estándar de Python: ejecutan una función especificada para cada elemento en un iterable que reciben como entrada (tanto la función como el iterable):\n",
        "\n",
        "```\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "num_list = [1,2,3,4]\n",
        "result = map(square, num_list)\n",
        "print('Mapped result is: ', list(result))\n",
        "\n",
        "Output:\n",
        ">> Mapped result is:  [1, 4, 9, 16]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XMtc1iK3BA9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import multiprocessing as mp\n",
        "\n",
        "def doubler(number):\n",
        "  \"\"\"\n",
        "  A doubling function that can be used by a process\n",
        "  \"\"\"\n",
        "  result = number * 2\n",
        "  proc = os.getpid()\n",
        "  print(f'{number} doubled to {result} by process id: {proc} ')\n",
        "  return result\n",
        "\n",
        "numbers = [5, 10, 15, 20, 25]\n",
        "\n",
        "# instantiate a pool of 3 processes\n",
        "pool = mp.Pool(processes=3)\n",
        "result = pool.map(doubler, numbers)\n",
        "pool.close()\n",
        "\n",
        "print(f'input data: {numbers}')\n",
        "print(f'results are in corresponding order: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK93oxbxBTef"
      },
      "source": [
        "En este ejemplo, la función `pool.map` funciona de la siguiente manera:\n",
        "\n",
        "1. **Paso 1: Crea un Pool con 3 procesos**\n",
        "2. **Paso 2: Asignando tareas**\n",
        "    - El Pool divide la lista [5, 10, 15, 20, 25] en tareas y las asigna a los 3 procesos.\n",
        "    - Inicialmente, los 3 procesos comienzan a trabajar en los primeros 3 números:\n",
        "        * *Process 1*: 5\n",
        "        * *Process 2*: 10\n",
        "        * *Process 3*: 15\n",
        "3. **Paso 3: Ejecución Paralela**\n",
        "    - Los 3 procesos ejecutan la function en paralelo.\n",
        "    - Cuando un process finaliza, el Pool le asigna el siguiente número disponible:\n",
        "        * Si *Process 3* finaliza primero, se le asigna el número 20.\n",
        "        * Si *Process 1* finaliza a continuación, se le asigna el número 25.\n",
        "\n",
        "4. **Paso 4: Recogida de Resultados**\n",
        "    - Aunque los procesos pueden finalizar en cualquier orden, `pool.map` garantiza que los resultados se devuelven en el orden correcto:\n",
        "        * El primer resultado corresponde a 5.\n",
        "        * El segundo resultado corresponde a 10.\n",
        "        * El tercer resultado corresponde a 15.\n",
        "        * El cuarto resultado corresponde a 20.\n",
        "        * El quinto resultado corresponde a 25."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qVyfsurW3XC"
      },
      "source": [
        "### Uso de Pool.map_async\n",
        "\n",
        "`pool.map_async` es la versión asíncrona de `pool.map`. Esto significa:\n",
        "\n",
        "- **No bloquea el programa principal**:\n",
        "    * A diferencia de `pool.map`, que espera a que todos los procesos finalicen antes de continuar, `pool.map_async` devuelve inmediatamente un objeto `AsyncResult` y permite que el programa principal continúe ejecutándose.\n",
        "- **Recuperando resultados**:\n",
        "    * Para obtener los resultados, debes llamar al método `.get()` en el objeto `AsyncResult`. Este método bloquea el programa principal hasta que todos los procesos hayan finalizado y los resultados estén disponibles.\n",
        "- **Orden de los resultados**:\n",
        "    * Aunque `pool.map_async` es asíncrono, garantiza que los resultados se devuelvan en el mismo orden que la lista de entrada. Esto es similar a `pool.map`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkgb8KteTrZg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import multiprocessing as mp\n",
        "import time\n",
        "\n",
        "def doubler(number):\n",
        "  \"\"\"\n",
        "  A doubling function that can be used by a process\n",
        "  \"\"\"\n",
        "  result = number * 2\n",
        "  proc = os.getpid()\n",
        "  print(f'{number} doubled to {result} by process id: {proc} ')\n",
        "  return result\n",
        "\n",
        "numbers = [5, 10, 15, 20, 25]\n",
        "\n",
        "# instantiate a pool of 3 processes\n",
        "pool = mp.Pool(processes=3)\n",
        "result = pool.map_async(doubler, numbers)\n",
        "pool.close()  # Don't accept more tasks\n",
        "\n",
        "####### Here we could do some stuff while the processes run in parallel...\n",
        "\n",
        "pool.join()   # Wait for all processes ending\n",
        "results = result.get()# recover the real output data from the result object\n",
        "\n",
        "print(f'input data: {numbers}')\n",
        "print(f'results are in corresponding order: {results}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfT69a1d7PGK"
      },
      "source": [
        "### Uso de Pool.starmap\n",
        "\n",
        "Con `Pool.starmap`, en lugar de un único parámetro, se pasan múltiples parámetros en forma de tuplas a la función que se ejecuta en paralelo.\n",
        "\n",
        "Así, al pasar un iterable como `[(1,2), (3,4), ...]` se obtiene `[func(1,2), func(3,4), ...]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_S38um97WeU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import multiprocessing as mp\n",
        "\n",
        "def doubler_adder(a, b):\n",
        "  result = a * 2 + b * 2\n",
        "  proc = os.getpid()\n",
        "  print(f'{a}  and {b} doubled and added to {result} by process id: {proc} ')\n",
        "  return result\n",
        "\n",
        "# numbers = [5, 10, 15, 20, 25]\n",
        "numbers_in_tuples = [(x,x+1) for x in range(0,10)] # [(0,1), (1,2), ....]\n",
        "\n",
        "# instantiate a pool of 3 processes\n",
        "pool = mp.Pool(processes=3)\n",
        "result = pool.starmap(doubler_adder, numbers_in_tuples)\n",
        "# with a single argument, starmap could also be used:\n",
        "# result = pool.starmap(doubler, [(5,), (10,), (15,), (20,), (25,)])\n",
        "pool.close()\n",
        "\n",
        "print(f'input data: {numbers_in_tuples}')\n",
        "print(f'results are in corresponding order: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekd8lKXX5bAF"
      },
      "source": [
        "Nota: Puedes obtener el mismo efecto utilizando `Pool.map` (en lugar de `Pool.starmap`), si haces el esfuerzo adicional de unir varios argumentos de la función objetivo en un único argumento (data objetct), como en el siguiente ejemplo, donde la función 'doubler_adder' ha sido modificada para aceptar solo 1 parámetro, que es, de hecho, una lista de los dos parámetros originales:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_qh1yE74waW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import multiprocessing as mp\n",
        "\n",
        "# function modified to take just a single parameter:\n",
        "def doubler_adder(a):\n",
        "  result = a[0] * 2 + a[1] * 2\n",
        "  proc = os.getpid()\n",
        "  print(f'{a[0]}  and {a[1]} doubled and added to {result} by process id: {proc} ')\n",
        "  return result\n",
        "\n",
        "# numbers = [5, 10, 15, 20, 25]\n",
        "numbers_in_list = [[x,x+1] for x in range(0,10)] # [[0,1], [1,2], ....]\n",
        "# instantiate a pool of 3 processes\n",
        "pool = mp.Pool(processes=3)\n",
        "result = pool.map(doubler_adder, numbers_in_list)\n",
        "pool.close()\n",
        "\n",
        "print(f'input data: {numbers_in_list}')\n",
        "print(f'results are in corresponding order: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhHskhSb_vWB"
      },
      "source": [
        "## Comparando Tiempos de Ejecución"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn4bkAq303WL"
      },
      "source": [
        "Los siguientes scripts comparan el enfoque bloqueante **blocking multiprocess** con el no bloqueante **non-blocking multiprocess** y la solución con un único proceso **single-process**, midiendo el tiempo de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRdx9dZ_jBEs"
      },
      "source": [
        "### 1. Enfoque simple:\n",
        "\n",
        "Sin ganancia de rendimiento en la ejecución en paralelo para tareas limitadas por I/O, tareas simples o pocas tareas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0Uz-F0LR-lX"
      },
      "outputs": [],
      "source": [
        "import multiprocessing as mp\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def f(x, y):\n",
        "    return (x+y)**(2)\n",
        "\n",
        "# generate 2 arrays of 1 million random integers between 1 and 10\n",
        "x = np.random.randint(1,10,1000000)\n",
        "y = np.random.randint(1,10,1000000)\n",
        "print(f'first values in x: {x[0:10]}')\n",
        "print(f'first values in y: {y[0:10]}')\n",
        "\n",
        "xy_tuple = [(int(x[i]),int(y[i])) for i in range(0,len(x))]\n",
        "print(f'first values in xy_tuple: {xy_tuple[0:10]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRSIfQixaBiU"
      },
      "outputs": [],
      "source": [
        "# generate a 2-process pool.starmap\n",
        "pool = mp.Pool(2)\n",
        "# Blocking multiprocess execution\n",
        "t0 = time.time()\n",
        "result1 = pool.starmap(f, xy_tuple)\n",
        "t1 = time.time()\n",
        "pool.close()\n",
        "# print results\n",
        "print(f'first values in result1: {result1[0:10]}')\n",
        "print(f'time for pool.starmap: {t1-t0}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jov29cS_RwEN"
      },
      "outputs": [],
      "source": [
        "# generate a 2-process pool.starmap_async\n",
        "pool = mp.Pool(2)\n",
        "# Non-blocking multiprocess execution \"in the background\"\n",
        "t0 = time.time()\n",
        "result2_ = pool.starmap_async(f, xy_tuple)\n",
        "pool.close()  # Don't accept more tasks\n",
        "\n",
        "####### Here we could do some stuff while the processes run in parallel...\n",
        "\n",
        "pool.join()   # Wait for all the process ending\n",
        "result2 = result2_.get()# recover the real output data from the result object\n",
        "t1 = time.time()\n",
        "# print results\n",
        "print(f'first values in result2: {result2[0:10]}')\n",
        "print(f'time for pool.starmap_async: {t1-t0}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Dj_tguzBtwb"
      },
      "outputs": [],
      "source": [
        "# Compare with the single-process solution: send data sequentially\n",
        "result3 = np.zeros(len(x), dtype=int)\n",
        "#result3 = np.zeros(len(x))\n",
        "t0 = time.time()\n",
        "for i in range(len(x)):\n",
        "  result3[i] = f(x[i],y[i])\n",
        "t1 = time.time()\n",
        "print(f'first values in result3: {result3[0:10]}')\n",
        "print(f'time for single-process: {t1-t0}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRwD44slSSEp"
      },
      "outputs": [],
      "source": [
        "# Compare with the single-process solution: using vectorized operators\n",
        "t0 = time.time()\n",
        "result3 = f(x,y)\n",
        "t1 = time.time()\n",
        "print(f'first values in result3: {result3[0:10]}')\n",
        "print(f'time for single-process: {t1-t0}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GKdUhtKP1En"
      },
      "source": [
        "Compara y analiza los tiempos obtenidos al ejecutar las diferentes versiones de los programas.\n",
        "\n",
        "- A primera vista, se esperaría que el tiempo de ejecución de las versiones paralelas fuese la mitad del requerido por la versión secuencial de un solo proceso del programa. ¿Has observado tal reducción en las mediciones de tiempo? Si no, ¿cuál es la razón?\n",
        "\n",
        "- Al comparar los tiempos de ejecución de las versiones paralelas sincrónica y asíncrona, ¿qué conclusiones puedes sacar?\n",
        "\n",
        "- ¿Qué versión del programa es más rápida? ¿Cuáles son las razones que hacen de esta versión la más optimizada?\n",
        "\n",
        "> **NOTA IMPORTANTE**\n",
        "> - Una versión paralela de un programa puede ser más lenta que una secuencial. Esto puede ocurrir cuando existe una gran sobrecarga debido al envío de datos a cada proceso.\n",
        "> - Cuando defines tareas relativamente simples (x+y)<sup>2</sup>, el tiempo empleado en enviar datos y recoger resultados es mucho mayor que el tiempo dedicado al cálculo real.\n",
        "> - Para aprovechar el procesamiento paralelo, debemos mantener la pool de procesos ocupada con tareas relativamente complejas y minimizar la sobrecarga de comunicación. Y, por supuesto, debemos usar un mayor número de procesadores físicos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0gpoNvtjXfO"
      },
      "source": [
        "### 2. Versión data-chunked.\n",
        "\n",
        "Como demostración, consulta el siguiente código, ligeramente modificado respecto al ejemplo anterior:\n",
        "\n",
        "**NOTA**:\n",
        "\n",
        "También haremos uso de los bloques `with`, conocidos como **context managers**. Un **context manager** es un constructo que permite asignar y liberar recursos automáticamente al entrar y salir de un bloque de código. La sentencia `with` asegura que las operaciones de setup y cleanup se gestionen correctamente, incluso si se producen excepciones dentro del bloque. En este caso, elimina la necesidad de llamar explícitamente a `pool.close()` y `pool.join()` al final de la sección paralela.\n",
        "\n",
        "El uso de **context managers** se recomienda generalmente en la programación en Python, pero es particularmente importante en la programación paralela.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn-fUEdG4kGK"
      },
      "outputs": [],
      "source": [
        "# This example defines a compute-intensive function and sends data in chunks\n",
        "# NOTE: Recommended to test this example in a (virtual) machine with 4 logical cores.\n",
        "import time\n",
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "\n",
        "# Generate 40 million random floats\n",
        "N = 40_000_000\n",
        "x = np.random.rand(N).astype(np.float64)\n",
        "\n",
        "# Create 4 chunks of 10 million elements each:\n",
        "chunk_size = 10_000_000\n",
        "chunks = [x[i:i + chunk_size] for i in range(0, N, chunk_size)]\n",
        "print(f\"Number of chunks: {len(chunks)}\")\n",
        "print(f\"Size of each chunk: {chunk_size}\")\n",
        "\n",
        "# Define a CPU-intensive function\n",
        "def heavy_function(array):\n",
        "    for _ in range(3):\n",
        "        array = (np.sin(array)+np.cos(array))**(array*array)\n",
        "    return np.sum(array)  # Just return the sum of the processed chunk\n",
        "\n",
        "# Multiprocessing - blocking version (Pool.map)\n",
        "def parallel_map(chunks_list, num_procs=4):\n",
        "    with mp.Pool(processes=num_procs) as pool:\n",
        "        results = pool.map(heavy_function, chunks_list)\n",
        "    return results\n",
        "\n",
        "# Multiprocessing - async version (Pool.map_async)\n",
        "def parallel_map_async(chunks_list, num_procs=4):\n",
        "    with mp.Pool(processes=num_procs) as pool:\n",
        "        async_result = pool.map_async(heavy_function, chunks_list)\n",
        "        results = async_result.get()  # Wait for processes to finish\n",
        "    return results\n",
        "\n",
        "# Single-process (serial) execution\n",
        "def serial_execution(chunks_list):\n",
        "    results = []\n",
        "    for chunk in chunks_list:\n",
        "        results.append(heavy_function(chunk))\n",
        "    return results\n",
        "\n",
        "# time all three approaches:\n",
        "# execute and time Parallel blocking code (Pool.map)\n",
        "start_time = time.time()\n",
        "results_map = parallel_map(chunks)\n",
        "end_time = time.time()\n",
        "print(f\"[Pool.map]     Elapsed time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# execute and time Parallel async code (Pool.map_async)\n",
        "start_time = time.time()\n",
        "results_map_async = parallel_map_async(chunks)\n",
        "end_time = time.time()\n",
        "print(f\"[map_async]    Elapsed time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "#execute and time Serial code\n",
        "start_time = time.time()\n",
        "results_serial = serial_execution(chunks)\n",
        "end_time = time.time()\n",
        "print(f\"[Single-process] Elapsed time: {end_time - start_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n6x6OYEZT0w"
      },
      "source": [
        "### 3. Otro ejemplo: descomposición en factores primos\n",
        "\n",
        "Un nuevo ejemplo, en este caso utilizando una tarea más compleja: la descomposición en factores primos de números grandes.\n",
        "\n",
        "En este caso, también estamos utilizando `tqdm` para proporcionar una barra de progreso que soporta tanto la ejecución single-process como la multi-process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcc_w-uhMANb"
      },
      "outputs": [],
      "source": [
        "# This example uses a function that computes prime factors of a number\n",
        "# NOTE: On a machine with just 1 physical core there won't be performance\n",
        "# gains, use an engine with more cores to perceive the gain in this example\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "from multiprocessing import Pool\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define a function to decompose a number into its prime factors\n",
        "def prime_factors(n):\n",
        "    factors = []\n",
        "    divisor = 2\n",
        "    while n > 1:\n",
        "        while n % divisor == 0:\n",
        "            factors.append(divisor)\n",
        "            n //= divisor\n",
        "        divisor += 1\n",
        "        if divisor * divisor > n and n > 1:\n",
        "            factors.append(n)\n",
        "            break\n",
        "    return factors\n",
        "\n",
        "# Create data to process (large numbers for factorization)\n",
        "# create a list of 100 random floating point numbers between 1e14 and 1e18\n",
        "data = np.random.uniform(1e10, 1e12, 100)\n",
        "\n",
        "# Single-process execution\n",
        "def single_process_execution(data):\n",
        "    results = []\n",
        "    for number in tqdm(data, desc=\"Single-process execution\"):\n",
        "        results.append(prime_factors(number))\n",
        "    return results\n",
        "\n",
        "# Multi-process execution with starmap\n",
        "def multi_process_execution(data):\n",
        "    with Pool(2) as pool:  # Use 2 processes\n",
        "        results = list(tqdm(pool.map(prime_factors, data), total=len(data), desc=\"Multi-process execution\"))\n",
        "    return results\n",
        "\n",
        "# Measure time for single process execution\n",
        "start_time = time.time()\n",
        "single_results = single_process_execution(data)\n",
        "single_duration = time.time() - start_time\n",
        "print(f\"Single-process execution time: {single_duration:.2f} seconds\")\n",
        "\n",
        "# Measure time for multi-process execution\n",
        "start_time = time.time()\n",
        "multi_results = multi_process_execution(data)\n",
        "multi_duration = time.time() - start_time\n",
        "print(f\"Multi-process execution time (2 cores): {multi_duration:.2f} seconds\")\n",
        "\n",
        "# Verify that the results are identical\n",
        "assert single_results == multi_results, \"Results do not match!\"\n",
        "print(\"Results are identical.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZD8fm_IVO9B"
      },
      "source": [
        "## Ejecutando varios scripts python en paralelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Io__C0k5IIKL"
      },
      "outputs": [],
      "source": [
        "%%file script1.py\n",
        "import os\n",
        "print(f'hello from script 1, executed by process {os.getpid()}.')\n",
        "f= open(\"file1.txt\",\"w+\")\n",
        "f.write(\"hello from script 1\")\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4orpbP-IUjn"
      },
      "outputs": [],
      "source": [
        "%%file script2.py\n",
        "import os\n",
        "\n",
        "print(f'hello from script 2, executed by process {os.getpid()}.')\n",
        "f= open(\"file2.txt\",\"w+\")\n",
        "f.write(\"hello from script 2\")\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBeCEqopIVP2"
      },
      "outputs": [],
      "source": [
        "%%file script3.py\n",
        "import os\n",
        "\n",
        "print(f'hello from script 3, executed by process {os.getpid()}.')\n",
        "f= open(\"file3.txt\",\"w+\")\n",
        "f.write(\"hello from script 3\")\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ8PZQ6DfZfa"
      },
      "source": [
        " Now, run 3 processes so that each process executes one of the python scripts in parallel with the other:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi_xB8mxIZxG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import multiprocessing as mp\n",
        "import subprocess\n",
        "\n",
        "script_list = ['script1.py', 'script2.py', 'script3.py']\n",
        "\n",
        "def run_python(process):\n",
        "  result = subprocess.run([\"python\", process], capture_output=True, text=True)\n",
        "  return result.stdout\n",
        "\n",
        "pool = mp.Pool(processes=3)\n",
        "results = pool.map(run_python, script_list)\n",
        "pool.close()\n",
        "\n",
        "print(f'results = {results}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-g9dOOv7GSf"
      },
      "source": [
        "## Uso de Pool.apply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LPXiHejexwt"
      },
      "source": [
        "``Pool.map`` y ``Pool.apply`` bloquearán el programa principal hasta que todos los procesos hayan finalizado, lo cual es muy útil si queremos obtener resultados en un orden particular para ciertas aplicaciones.\n",
        "\n",
        "En contraste, las variantes async enviarán todos los procesos a la vez y recuperarán los resultados tan pronto como hayan finalizado. Otra diferencia es que necesitamos usar el método get después de la llamada a apply_async() para obtener los valores de retorno de los procesos finalizados.\n",
        "\n",
        "El orden de los resultados no está garantizado que sea el mismo que el orden de las llamadas a ``Pool.apply_async``.\n",
        "\n",
        "Observa también que se podrían llamar a varias funciones diferentes con ``Pool.apply_async`` (no todas las llamadas necesitan usar la misma función). En contraste, ``Pool.map`` aplica la misma función a muchos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLguzlQZ-rbu"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def doubler(number):\n",
        "  \"\"\"\n",
        "  A doubling function that can be used by a process\n",
        "  \"\"\"\n",
        "  result = number * 2\n",
        "  proc = os.getpid()\n",
        "  print(f'{number} doubled to {result} by process id: {proc} ')\n",
        "  return result\n",
        "\n",
        "numbers = [5, 10, 15, 20, 25]\n",
        "\n",
        "results =[]\n",
        "pool = Pool(processes=3)\n",
        "for i,number in enumerate(numbers): # note the for-loop!!! calling apply_async creates just a single process\n",
        "  results.append(pool.apply_async(doubler, (numbers[i],)).get(timeout=1))\n",
        "\n",
        "print(results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}